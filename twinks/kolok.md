# Kolo(bo)k

Вот ответы на вопросы к коллоквиуму, составленные исключительно на основе предоставленного конспекта лекций.

## Введение в теорию вероятностей

**Предмет и метод теории вероятностей. Пространство элементарных событий.**
* **Предмет:** Теория вероятностей изучает закономерности массовых случайных явлений. Цель — прогнозировать средний суммарный результат массы однородных явлений, минуя сложное исследование отдельного случая.
* **Метод:** Учет основных факторов и анализ случайных возмущений, приводящих к статистическим закономерностям (устойчивости частот).
* **Пространство элементарных событий (Ω):** Множество всех возможных исходов опыта Ω = {w₁, w₂, ..., wₙ}, где wᵢ — элементарное событие.


**Случайные события и их классификация.**
* **Случайное событие:** Факт, который в опыте может произойти или нет. Любое событие A есть подмножество Ω.
* **Достоверное событие:** Происходит в каждом опыте (A = Ω).
* **Невозможное событие:** Никогда не происходит (A = ∅).
* **Несовместные события:** Не могут произойти одновременно (A · B = ∅).
* **Полная группа:** События попарно несовместны и в сумме образуют достоверное событие.

**Алгебра событий.**
* **Противоположное событие (A̅ или не-A):** Состоит в невыполнении A.
* **Сумма (A+B):** Происходит либо A, либо B, либо оба.
* **Произведение (A · B):** Происходят A и B одновременно.

**Простейшие вероятностные модели.**
* **Классическая:** Число исходов конечно, они несовместны и равновозможны (схема случаев).
* **Геометрическая:** Применима к испытаниям с бесконечным числом исходов (попадание точки в область).

**Понятие вероятности в классической модели. Свойства вероятностей.**
* **Определение:** Отношение числа благоприятных исходов (m) к общему числу исходов (n): p(A) = m/n.
* **Свойства (Аксиомы):**
    1.  0 ≤ p(A) ≤ 1.
    2.  p(∅) = 0, p(Ω) = 1.
    3.  Вероятность суммы несовместных событий равна сумме их вероятностей.

**Непосредственный подсчет вероятности. Элементы комбинаторики.**
Для подсчета m и n используются формулы комбинаторики для множества из n элементов:
* **Размещения (Aₙʳ):** Упорядоченная выборка. Aₙʳ = n!/(n-r)!.
* **Перестановки (Pₙ):** Размещения при n = r. Pₙ = n!.
* **Сочетания (Cₙʳ):** Неупорядоченная выборка. Cₙʳ = n!/(r!(n-r)!).

**Частость и статистические вероятности.**
При многократном повторении опыта частота появления события (m/n) стабилизируется и приближается к вероятности p. Это свойство «устойчивости частот» является базой для применения статистических методов.

---

## Теоремы сложения и умножения вероятностей

**Сумма событий. Теоремы сложения.**
* **Теорема (несовместные):** p(A+B) = p(A) + p(B).
* **Теорема (совместные):** p(A+B) = p(A) + p(B) - p(AB).

**Произведение событий. Условная вероятность. Независимость.**
* **Условная вероятность p(B/A):** Вероятность события B при условии, что A произошло.
* **Независимость:** События независимы, если p(B/A) = p(B).

**Теоремы умножения вероятности.**
* **Общая:** p(AB) = p(A)·p(B/A).
* **Для независимых:** p(AB) = p(A)·p(B).

**Вероятность появления хотя бы одного из *n* событий.**
Вероятность суммы совместных событий удобнее вычислять через противоположные: p(A₁ + ... + Aₙ) = 1 - q₁·q₂·...·qₙ, где qᵢ = 1 - pᵢ.

**Вероятность безотказной работы сети.**
* **Последовательное соединение:** p_sys = p₁ · p₂ · ... · pₙ.
* **Параллельное соединение:** p_sys = 1 - q₁ · q₂ · ... · qₙ.

---

## Формулы полной вероятности и Байеса. Теоремы в схеме Бернулли

**Формула полной вероятности.**
Если событие A может произойти только с одной из гипотез Hᵢ, образующих полную группу (Σ p(Hᵢ) = 1), то p(A) = Σᵢ₌₁ⁿ p(Hᵢ)·p(A/Hᵢ).

**Формула Байеса.**
Позволяет пересчитать вероятности гипотез после опыта (апостериорные):
p(Hᵢ/A) = (p(Hᵢ)·p(A/Hᵢ))/(p(A)), где p(A) — полная вероятность.

**Повторные независимые испытания.**
* **Формула Бернулли:** Вероятность того, что в n опытах событие наступит ровно k раз: P(n, k) = Cₙᵏ · pᵏ · qⁿ⁻ᵏ.
* **Формула Пуассона:** Применяется при n → ∞, p → 0 (малая вероятность): P(n, k) ≈ (aᵏ · e⁻ᵃ)/(k!), где a = n·p.

**Наивероятнейшее число наступления события.**
Число k₀, которому соответствует максимальная вероятность, определяется условием: n·p - q ≤ k₀ ≤ n·p + p.

**Теоремы Муавра-Лапласа (при больших n).**
* **Локальная:** P(n, k) ≈ (1/√(n·p·q)) · φ(x), где φ(x) — четная функция.
* **Интегральная:** Вероятность попадания числа событий в интервал: P(k₁ ≤ k ≤ k₂) ≈ Φ(x₂) - Φ(x₁).

---

## Дискретные и непрерывные случайные величины


**Дискретная случайная величина (ДСВ). Закон распределения.**
* **ДСВ:** Множество значений счетное (можно пронумеровать).
* **Закон распределения (ряд):** Таблица соответствия значений xᵢ и их вероятностей pᵢ, где Σ pᵢ = 1.
* **Графическая иллюстрация:** Многоугольник вероятностей.

**Функция распределения F(x).**
* **Определение:** Вероятность того, что величина X примет значение меньше x: F(x) = p(X < x).
* **Свойства:**
    1.  0 ≤ F(x) ≤ 1.
    2.  F(-∞) = 0, F(+∞) = 1.
    3.  Неубывающая функция.
* **Особенность для ДСВ:** Разрывная ступенчатая функция.
* **Вероятность попадания в промежуток:** p(a ≤ X < b) = F(b) - F(a).

**Непрерывная случайная величина (НСВ).**
* **НСВ:** Множество значений несчетное, F(x) непрерывна и дифференцируема.
* **Плотность вероятности f(x):** Первая производная от функции распределения: f(x) = F'(x).
* **Свойства плотности:**
    1.  f(x) ≥ 0.
    2.  Условие нормировки: ∫[от -∞ до +∞] f(x) dx = 1.
* **Вероятность попадания в промежуток (НСВ):** p(a ≤ X < b) = ∫ₐᵇ f(x) dx.

---

## Числовые характеристики случайных величин

**Характеристики положения и рассеяния.**
Закон распределения дает полное описание, но часто достаточно числовых параметров (моменты).

**Моменты.**
* **Начальный момент k-го порядка (αₖ):** M[Xᵏ].
* **Центрированная величина:** X° = X - mₓ.
* **Центральный момент k-го порядка (μₖ):** M[(X-mₓ)ᵏ].

**Математическое ожидание (mₓ или M[X]).**
* **Смысл:** Среднее взвешенное значение (центр распределения).
* **Формулы:** Σ xᵢ·pᵢ (для ДСВ) или ∫[от -∞ до +∞] x·f(x) dx (для НСВ).
* **Свойства:**
    1.  M[c] = c.
    2.  M[c·X] = c·M[X].
    3.  M[X+Y] = M[X] + M[Y] (для суммы).

**Дисперсия (D[X]) и СКО.**
* **Дисперсия:** Характеризует меру разброса значений. D[X] = M[(X-mₓ)²] = M[X²] - (M[X])².
* **Свойства:** D[c] = 0, D[X+c] = D[X], D[c·X] = c²·D[X].
* **Среднее квадратическое отклонение (СКО, σ):** σₓ = √(D[X]). Имеет размерность самой величины.

---

## Некоторые законы распределения ДСВ

**Биномиальный закон.**
* **Суть:** Схема Бернулли (n опытов).
* **Вероятность:** pᵢ = Cₙᵢ · pⁱ · qⁿ⁻ᵢ.
* **Характеристики:** mₓ = n·p, Dₓ = n·p·q.

**Закон Пуассона.**
* **Суть:** Предельный случай биномиального при n → ∞. Также описывает поток событий.
* **Вероятность:** pᵢ = (aⁱ · e⁻ᵃ)/(i!).
* **Характеристики:** mₓ = a, Dₓ = a.
* **Простейший поток:** Стационарный (плотность λ постоянна), ординарный, без последействия. Параметр a = λ·t.

**Геометрическое распределение.**
* **Суть:** Число опытов до первого появления события.
* **Вероятность:** pᵢ = qⁱ · p.
* **Характеристики:** mₓ = q/p, Dₓ = q/p².

*Примечание: Гипергеометрическое распределение в предоставленном конспекте не описано.*

---

## Некоторые законы распределения НСВ

**Равномерный закон.**
* **Плотность:** f(x) = 1/(b-a) на отрезке [a, b], иначе 0.
* **Характеристики:** mₓ = (a+b)/2, Dₓ = (b-a)²/12.

**Показательный (экспоненциальный) закон.**
* **Плотность:** f(t) = λ·e^(-λ·t) при t ≥ 0.
* **Характеристики:** m_T = 1/λ, D_T = 1/λ².


**Нормальный закон (Гаусса).**
* **Плотность:** f(x) = (1/(σ·√(2π))) · exp(-(x-m)²/(2σ²)).
* **Характеристики:** mₓ = m, Dₓ = σ².
* **Правило трех сигм:** Практически все значения лежат в интервале [m-3σ; m+3σ].

**Функция Лапласа.**
* Φ(x) = (1/√(2π)) · ∫₀ˣ e^(-t²/2) dt. Нечетная (Φ(-x) = -Φ(x)), Φ(0) = 0, Φ(∞) = 0.5.

---

## Двухмерная случайная величина

**Двухмерная функция распределения.**
* **Определение:** F(x, y) = p(X < x, Y < y).
* **Свойства:** 0 ≤ F ≤ 1, F(-∞, -∞) = 0, F(+∞, +∞) = 1, неубывающая по каждому аргументу.

**Матрица и плотность распределения.**
* **Матрица (для дискретных):** Таблица вероятностей pᵢⱼ, сумма всех элементов равна 1.
* **Плотность (для непрерывных):** f(x, y) = ∂²F(x,y)/(∂x·∂y). Объем под поверхностью равен 1.

**Переход к одномерным законам.**
* Для функции: F₁(x) = F(x, +∞).
* Для плотности: f₁(x) = ∫[от -∞ до +∞] f(x, y) dy.

**Зависимость.**
* **Независимые СВ:** f(x, y) = f(x)·f(y) или F(x, y) = F(x)·F(y).
* **Условные законы:** Распределение одной величины при фиксации другой. f(x/y) = f(x, y) / f₂(y).

**Числовые характеристики.**
* **Смешанный начальный момент:** αₖ,ₛ = M[Xᵏ·Yˢ].
* **Смешанный центральный момент:** μₖ,ₛ = M[(X-mₓ)ᵏ·(Y-mᵧ)ˢ].

**Корреляционный момент (ковариация).**
* K_XY = μ₁,₁ = M[(X-mₓ)·(Y-mᵧ)].
* Характеризует связь и рассеяние. Для независимых величин K_XY = 0.

**Коэффициент корреляции.**
* R_XY = K_XY/(σₓ·σᵧ).
* **Свойства:**
    1.  |R_XY| ≤ 1.
    2.  |R_XY| = 1 при линейной функциональной зависимости.
    3.  R_XY = 0 для независимых величин.

---

## Закон больших чисел (ЗБЧ)

* **Суть:** При большом числе опытов среднее значение случайной величины теряет случайный характер и стремится к константе.
* **Неравенство Чебышева:** p(|X-mₓ| ≥ ε) ≤ D[X]/ε². Дает верхнюю границу вероятности отклонения.
* **Теорема Чебышева:** Среднее арифметическое независимых величин сходится по вероятности к их математическому ожиданию.
* **Теорема Бернулли:** Частота события сходится по вероятности к его вероятности p.

---

## Центральная предельная теорема (ЦПТ)


* **Формулировка:** Если складывается много независимых случайных величин, имеющих сравнимые дисперсии (ни одна не доминирует), то закон распределения их суммы неограниченно приближается к **нормальному закону**.
* **Параметры суммы:** M_Σ = Σ mᵢ, D_Σ = Σ Dᵢ.
* Практически нормальным распределение считается при n > 10...20.
